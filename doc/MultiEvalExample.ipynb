{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.batch import MultiEval\n",
    "from lenskit.crossfold import partition_users, SampleN\n",
    "from lenskit.algorithms import basic, als\n",
    "from lenskit.datasets import MovieLens\n",
    "from lenskit import topn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the train-test pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('ml-latest-small')\n",
    "pairs = list(partition_users(mlsmall.ratings, 5, SampleN(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and run the `MultiEval` experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:383: FutureWarning: RangeIndex._start is deprecated and will be removed in a future version. Use RangeIndex.start instead\n",
      "  'start': level._start,\n",
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:384: FutureWarning: RangeIndex._stop is deprecated and will be removed in a future version. Use RangeIndex.stop instead\n",
      "  'stop': level._stop,\n",
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:385: FutureWarning: RangeIndex._step is deprecated and will be removed in a future version. Use RangeIndex.step instead\n",
      "  'step': level._step\n",
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:383: FutureWarning: RangeIndex._start is deprecated and will be removed in a future version. Use RangeIndex.start instead\n",
      "  'start': level._start,\n",
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:384: FutureWarning: RangeIndex._stop is deprecated and will be removed in a future version. Use RangeIndex.stop instead\n",
      "  'stop': level._stop,\n",
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lkpy-dev\\lib\\site-packages\\pyarrow\\pandas_compat.py:385: FutureWarning: RangeIndex._step is deprecated and will be removed in a future version. Use RangeIndex.step instead\n",
      "  'step': level._step\n"
     ]
    }
   ],
   "source": [
    "eval = MultiEval('my-eval', recommend=20)\n",
    "eval.add_datasets(pairs, name='ML-Small')\n",
    "eval.add_algorithms(basic.Popular(), name='Pop')\n",
    "eval.add_algorithms([als.BiasedMF(f) for f in [20, 30, 40, 50]],\n",
    "                    attrs=['features'], name='ALS')\n",
    "eval.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the experiment is run, we can read its outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Partition</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>AlgoStr</th>\n",
       "      <th>name</th>\n",
       "      <th>TrainTime</th>\n",
       "      <th>PredTime</th>\n",
       "      <th>RecTime</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>Popular</td>\n",
       "      <td>Popular</td>\n",
       "      <td>Pop</td>\n",
       "      <td>0.571511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=20, regularization=0.1)</td>\n",
       "      <td>ALS</td>\n",
       "      <td>4.358745</td>\n",
       "      <td>0.236710</td>\n",
       "      <td>0.492864</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=30, regularization=0.1)</td>\n",
       "      <td>ALS</td>\n",
       "      <td>0.298771</td>\n",
       "      <td>0.239025</td>\n",
       "      <td>0.565233</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=40, regularization=0.1)</td>\n",
       "      <td>ALS</td>\n",
       "      <td>0.402154</td>\n",
       "      <td>0.237375</td>\n",
       "      <td>0.638256</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=50, regularization=0.1)</td>\n",
       "      <td>ALS</td>\n",
       "      <td>0.489437</td>\n",
       "      <td>0.240399</td>\n",
       "      <td>0.634760</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DataSet  Partition AlgoClass  \\\n",
       "RunId                                  \n",
       "1      ML-Small          1   Popular   \n",
       "2      ML-Small          1  BiasedMF   \n",
       "3      ML-Small          1  BiasedMF   \n",
       "4      ML-Small          1  BiasedMF   \n",
       "5      ML-Small          1  BiasedMF   \n",
       "\n",
       "                                             AlgoStr name  TrainTime  \\\n",
       "RunId                                                                  \n",
       "1                                            Popular  Pop   0.571511   \n",
       "2      als.BiasedMF(features=20, regularization=0.1)  ALS   4.358745   \n",
       "3      als.BiasedMF(features=30, regularization=0.1)  ALS   0.298771   \n",
       "4      als.BiasedMF(features=40, regularization=0.1)  ALS   0.402154   \n",
       "5      als.BiasedMF(features=50, regularization=0.1)  ALS   0.489437   \n",
       "\n",
       "       PredTime   RecTime  features  \n",
       "RunId                                \n",
       "1           NaN  0.374972       NaN  \n",
       "2      0.236710  0.492864      20.0  \n",
       "3      0.239025  0.565233      30.0  \n",
       "4      0.237375  0.638256      40.0  \n",
       "5      0.240399  0.634760      50.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace=True)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>321.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318</td>\n",
       "      <td>311.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260</td>\n",
       "      <td>288.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>269.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  score  user  rank  RunId\n",
       "0   296  321.0     5     1      1\n",
       "1   318  311.0     5     2      1\n",
       "2   593  300.0     5     3      1\n",
       "3   260  288.0     5     4      1\n",
       "4   480  269.0     5     5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg\n",
       "user RunId             \n",
       "1    11      20.0   0.0\n",
       "     12      20.0   0.0\n",
       "     13      20.0   0.0\n",
       "     14      20.0   0.0\n",
       "     15      20.0   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "ndcg = rla.compute(recs, truth)\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Popular</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg AlgoClass  features\n",
       "user RunId                                 \n",
       "1    11      20.0   0.0   Popular       NaN\n",
       "     12      20.0   0.0  BiasedMF      20.0\n",
       "     13      20.0   0.0  BiasedMF      30.0\n",
       "     14      20.0   0.0  BiasedMF      40.0\n",
       "     15      20.0   0.0  BiasedMF      50.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg.join(runs[['AlgoClass', 'features']], on='RunId')\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Popular algorithm has NaN feature count, which `groupby` doesn't like; let's fill those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg.loc[ndcg['AlgoClass'] == 'Popular', 'features'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can compute the overall average performance for each algorithm configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlgoClass  features\n",
       "BiasedMF   20.0        0.011101\n",
       "           30.0        0.015509\n",
       "           40.0        0.015952\n",
       "           50.0        0.018086\n",
       "Popular    0.0         0.082958\n",
       "Name: ndcg, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg.groupby(['AlgoClass', 'features'])['ndcg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
